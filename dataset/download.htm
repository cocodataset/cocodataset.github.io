<!------------------------------------------------------------------------------------------------>
<div class="column3">
  <p class="fontTitle">Tools</p>
  <p class="fontBig"><a href="https://github.com/pdollar/coco" target="_blank">Matlab+Python+Lua APIs</a></p>
  <p class="fontSmall">V2.0 of the API was completed 07/2015 and includes detection eval code. The Lua API, added 05/2016, supports only load and view functionality (no eval code).</p>
</div>
<div class="columnSpacer"></div>
<div class="column3">
  <p class="fontTitle">Images</p>
  <p class="fontSmall">
    <a href="http://msvocds.blob.core.windows.net/coco2014/train2014.zip">2014 Training images [80K/13GB]</a><br/><br/>
    <a href="http://msvocds.blob.core.windows.net/coco2014/val2014.zip">2014 Val. images [40K/6.2GB]</a><br/><br/>
    <a href="http://msvocds.blob.core.windows.net/coco2014/test2014.zip">2014 Testing images [40K/6.2GB]</a><br/><br/>
    <a href="http://msvocds.blob.core.windows.net/coco2015/test2015.zip">2015 Testing images [80K/12.4G]</a>
  </p>
</div>
<div class="column3">
  <p class="fontTitle">Annotations</p>
  <p class="fontSmall">
    <a href="http://msvocds.blob.core.windows.net/annotations-1-0-3/instances_train-val2014.zip">2014 Train/Val object instances [158MB]</a><br/><br/>
    <a href="http://msvocds.blob.core.windows.net/annotations-1-0-3/person_keypoints_trainval2014.zip">2014 Train/Val person keypoints [70MB]</a><br/><br/>
    <a href="http://msvocds.blob.core.windows.net/annotations-1-0-3/captions_train-val2014.zip">2014 Train/Val image captions [18.8MB]</a><br/><br/>
    <a href="http://msvocds.blob.core.windows.net/annotations-1-0-4/image_info_test2014.zip">2014 Testing Image info [0.74MB]</a><br/><br/>
    <a href="http://msvocds.blob.core.windows.net/annotations-1-0-4/image_info_test2015.zip">2015 Testing Image info [1.83MB]</a><br/><br/>
    Note: annotations updated on 07/23/2015 with the addition of a "coco_url" field (for allowing of direct downloads of individual images).
  </p>
</div>

<!------------------------------------------------------------------------------------------------>
<p class="fontTitle">1. Overview</p>
<p>The 2014 Testing Images are for the <a href="#captions-challenge2015">COCO Captioning Challenge</a>, while the 2015 Testing Images are for the <a href="#detections-challenge2016">Detection</a> and <a href="#keypoints-challenge2016">Keypoint</a> Challenges. The train and val data are common to all challenges. Note also that as an alternative to downloading the large image zip files, individual images may be downloaded from the COCO website using the "coco_url" field specified in the image info struct (see details below).</p>
<p>Please follow the instructions in the <a href="https://github.com/pdollar/coco" target="_blank">README</a> to download and setup the COCO data (annotations and images). By downloading this dataset, you agree to our <a href="/termsofuse" target="_blank">Terms of Use</a>.</p>

<!------------------------------------------------------------------------------------------------>
<p class="fontTitle">2. COCO API</p>
<p>The COCO API assists in loading, parsing, and visualizing annotations in COCO. The API supports object instance, object keypoint, and image caption annotations (for captions not all functionality is defined). For additional details see: <a href="https://github.com/pdollar/coco/blob/master/MatlabAPI/CocoApi.m" target="_blank">CocoApi.m</a>, <a href="https://github.com/pdollar/coco/blob/master/PythonAPI/pycocotools/coco.py" target="_blank">coco.py</a>, and <a href="https://github.com/pdollar/coco/blob/master/LuaAPI/CocoApi.lua" target="_blank">CocoApi.lua</a> for Matlab, Python, and Lua code, respectively, and also the <a href="https://github.com/pdollar/coco/blob/master/PythonAPI/pycocoDemo.ipynb" target="_blank">Python API demo</a>.</p>
<div class="json">
  <div>Throughout the API "ann"=annotation, "cat"=category, and "img"=image.</div>
  <div class="jsonkfunc">download</div><div class="jsonvtxt">Download COCO images from mscoco.org server.</div>
  <div class="jsonkfunc">getAnnIds</div><div class="jsonvtxt">Get ann ids that satisfy given filter conditions.</div>
  <div class="jsonkfunc">getCatIds</div><div class="jsonvtxt">Get cat ids that satisfy given filter conditions.</div>
  <div class="jsonkfunc">getImgIds</div><div class="jsonvtxt">Get img ids that satisfy given filter conditions.</div>
  <div class="jsonkfunc">loadAnns</div><div class="jsonvtxt">Load anns with the specified ids.</div>
  <div class="jsonkfunc">loadCats</div><div class="jsonvtxt">Load cats with the specified ids.</div>
  <div class="jsonkfunc">loadImgs</div><div class="jsonvtxt">Load imgs with the specified ids.</div>
  <div class="jsonkfunc">loadRes</div><div class="jsonvtxt">Load algorithm results and create API for accessing them.</div>
  <div class="jsonkfunc">showAnns</div><div class="jsonvtxt">Display the specified annotations.</div>
</div>

<!------------------------------------------------------------------------------------------------>
<p class="fontTitle">3. MASK API</p>
<p>COCO provides segmentation masks for every object instance. This creates two challenges: storing masks compactly and performing mask computations efficiently. We solve both challenges using a custom Run Length Encoding (RLE) scheme. The size of the RLE representation is proportional to the number of boundaries pixels of a mask and operations such as area, union, or intersection can be computed efficiently directly on the RLE. Specifically, assuming fairly simple shapes, the RLE representation is O(&radic;n) where n is number of pixels in the object, and common computations are likewise O(&radic;n). Naively computing the same operations on the decoded masks (stored as an array) would be O(n).</p>
<p>The MASK API provides an interface for manipulating masks stored in RLE format. The API is defined below, for additional details see: <a href="https://github.com/pdollar/coco/blob/master/MatlabAPI/MaskApi.m" target="_blank">MaskApi.m</a>, <a href="https://github.com/pdollar/coco/blob/master/PythonAPI/pycocotools/mask.py" target="_blank">mask.py</a>, or <a href="https://github.com/pdollar/coco/blob/master/LuaAPI/MaskApi.lua" target="_blank">MaskApi.lua</a>. Finally, we note that a majority of ground truth masks are stored as polygons (which are quite compact), these polygons are converted to RLE when needed.</p>
<div class="json">
  <div class="jsonkfunc">encode</div><div class="jsonvtxt">Encode binary masks using RLE.</div>
  <div class="jsonkfunc">decode</div><div class="jsonvtxt">Decode binary masks encoded via RLE.</div>
  <div class="jsonkfunc">merge</div><div class="jsonvtxt">Compute union or intersection of encoded masks.</div>
  <div class="jsonkfunc">iou</div><div class="jsonvtxt">Compute intersection over union between masks.</div>
  <div class="jsonkfunc">area</div><div class="jsonvtxt">Compute area of encoded masks.</div>
  <div class="jsonkfunc">toBbox</div><div class="jsonvtxt">Get bounding boxes surrounding encoded masks.</div>
  <div class="jsonkfunc">frBbox</div><div class="jsonvtxt">Convert bounding boxes to encoded masks.</div>
  <div class="jsonkfunc">frPoly</div><div class="jsonvtxt">Convert polygon to encoded mask.</div>
</div>

<!------------------------------------------------------------------------------------------------>
<p class="fontTitle">4. Annotation format</p>
<p>COCO currently has three annotation types: object instances, object keypoints, and image captions. The annotations are stored using the <a href="http://json.org/" target="_blank">JSON</a> file format. All annotations share the basic data structure below:</p>
<div class="json">
  <div class="jsonreg">{</div>
  <div class="jsonk">"info"           </div><div class="jsonv">: info,</div>
  <div class="jsonk">"images"         </div><div class="jsonv">: [image],</div>
  <div class="jsonk">"annotations"    </div><div class="jsonv">: [annotation],</div>
  <div class="jsonk">"licenses"       </div><div class="jsonv">: [license],</div>
  <div class="jsonreg">}</div>
  <br/>
  <div class="jsonreg">info{</div>
  <div class="jsonk">"year"           </div><div class="jsonv">: int,</div>
  <div class="jsonk">"version"        </div><div class="jsonv">: str,</div>
  <div class="jsonk">"description"    </div><div class="jsonv">: str,</div>
  <div class="jsonk">"contributor"    </div><div class="jsonv">: str,</div>
  <div class="jsonk">"url"            </div><div class="jsonv">: str,</div>
  <div class="jsonk">"date_created"   </div><div class="jsonv">: datetime,</div>
  <div class="jsonreg">}</div>
  <br/>
  <div class="jsonreg">image{</div>
  <div class="jsonk">"id"             </div><div class="jsonv">: int,</div>
  <div class="jsonk">"width"          </div><div class="jsonv">: int,</div>
  <div class="jsonk">"height"         </div><div class="jsonv">: int,</div>
  <div class="jsonk">"file_name"      </div><div class="jsonv">: str,</div>
  <div class="jsonk">"license"        </div><div class="jsonv">: int,</div>
  <div class="jsonk">"flickr_url"     </div><div class="jsonv">: str,</div>
  <div class="jsonk">"coco_url"       </div><div class="jsonv">: str,</div>
  <div class="jsonk">"date_captured"  </div><div class="jsonv">: datetime,</div>
  <div class="jsonreg">}</div>
  <br/>
  <div class="jsonreg">license{</div>
  <div class="jsonk">"id"             </div><div class="jsonv">: int,</div>
  <div class="jsonk">"name"           </div><div class="jsonv">: str,</div>
  <div class="jsonk">"url"            </div><div class="jsonv">: str,</div>
  <div class="jsonreg">}</div>
</div>
<p>The data structures specific to the various annotation types are described below.</p>

<!------------------------------------------------------------------------------------------------>
<p class="fontSubtitle">4.1. Object Instance Annotations</p>
<p>Each instance annotation contains a series of fields, including the category id and segmentation mask of the object. The segmentation format depends on whether the instance represents a single object (iscrowd=0 in which case polygons are used) or a collection of objects (iscrowd=1 in which case RLE is used). Note that a single object (iscrowd=0) may require multiple polygons, for example if occluded. Crowd annotations (iscrowd=1) are used to label large groups of objects (e.g. a crowd of people). In addition, an enclosing bounding box is provided for each object (box coordinates are measured from the top left image corner and are 0-indexed). Finally, the categories field of the annotation structure stores the mapping of category id to category and supercategory names. See also the <a href="#detections-challenge2016">Detection Challenge</a>.</p>
<div class="json">
  <div class="jsonreg">annotation{</div>
  <div class="jsonk">"id"             </div><div class="jsonv">: int,</div>
  <div class="jsonk">"image_id"       </div><div class="jsonv">: int,</div>
  <div class="jsonk">"category_id"    </div><div class="jsonv">: int,</div>
  <div class="jsonk">"segmentation"   </div><div class="jsonv">: RLE or [polygon],</div>
  <div class="jsonk">"area"           </div><div class="jsonv">: float,</div>
  <div class="jsonk">"bbox"           </div><div class="jsonv">: [x,y,width,height],</div>
  <div class="jsonk">"iscrowd"        </div><div class="jsonv">: 0 or 1,</div>
  <div class="jsonreg">}</div>
  <br/>
  <div class="jsonreg">categories[{</div>
  <div class="jsonk">"id"             </div><div class="jsonv">: int,</div>
  <div class="jsonk">"name"           </div><div class="jsonv">: str,</div>
  <div class="jsonk">"supercategory"  </div><div class="jsonv">: str,</div>
  <div class="jsonreg">}]</div>
</div>

<!------------------------------------------------------------------------------------------------>
<p class="fontSubtitle">4.2. Object Keypoint Annotations</p>
<p>A keypoint annotation contains all the data of the object annotation (including id, bbox, etc.) and two additional fields. First, "keypoints" is a length 3k array where k is the total number of keypoints defined for the category. Each keypoint has a 0-indexed location x,y and a visibility flag v defined as v=0: not labeled (in which case x=y=0), v=1: labeled but not visible, and v=2: labeled and visible. A keypoint is considered visible if it falls inside the object segment. "num_keypoints" indicates the number of labeled keypoints (v>0) for a given object (many objects, e.g. crowds and small objects, will have num_keypoints=0). Finally, for each category, the categories struct has two additional fields: "keypoints," which is a length k array of keypoint names, and "skeleton", which defines connectivity via a list of keypoint edge pairs and is used for visualization. Currently keypoints are only labeled for the person category (for most medium/large non-crowd person instances). See also the <a href="#keypoints-challenge2016">Keypoint Challenge</a>.</p>
<div class="json">
  <div class="jsonreg">annotation{</div>
  <div class="jsonk">"keypoints"        </div><div class="jsonv">: [x1,y1,v1,...],</div>
  <div class="jsonk">"num_keypoints"    </div><div class="jsonv">: int,</div>
  <div class="jsonk">"[cloned]"         </div><div class="jsonv">: ...,</div>
  <div class="jsonreg">}</div>
  <br/>
  <div class="jsonreg">categories[{</div>
  <div class="jsonk">"keypoints"        </div><div class="jsonv">: [str],</div>
  <div class="jsonk">"skeleton"         </div><div class="jsonv">: [edge],</div>
  <div class="jsonk">"[cloned]"         </div><div class="jsonv">: ...,</div>
  <div class="jsonreg">}]</div>
  <br/>
  "[cloned]": denotes fields copied from object instance annotations defined in 4.1.</div>
</div>

<!------------------------------------------------------------------------------------------------>
<p class="fontSubtitle">4.3. Image Caption Annotations</p>
<p>These annotations are used to store image captions. Each caption describes the specified image and each image has at least 5 captions (some images have more). See also the <a href="#captions-challenge2015">Captioning Challenge</a>.</p>
<div class="json">
  <div class="jsonreg">annotation{</div>
  <div class="jsonk">"id"               </div><div class="jsonv">: int,</div>
  <div class="jsonk">"image_id"         </div><div class="jsonv">: int,</div>
  <div class="jsonk">"caption"          </div><div class="jsonv">: str,</div>
  <div class="jsonreg">}</div>
</div>
